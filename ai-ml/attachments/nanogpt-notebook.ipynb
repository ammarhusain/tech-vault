{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ammarh/anaconda3/envs/hf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ammarh/anaconda3/envs/hf/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.0\n",
      "number of parameters: 123.65M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 1.51MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 548M/548M [00:18<00:00, 29.5MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 932kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No meta.pkl found, assuming GPT-2 encodings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_not_equal\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/2f2cd822-4d3c-11ee-b057-aead88ae2785/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":253:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W50257 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/2f2cd822-4d3c-11ee-b057-aead88ae2785/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W50257 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ammarh/Library/Mobile Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus Areas/ai-ml/attachments/nanogpt-notebook.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ammarh/Library/Mobile%20Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus%20Areas/ai-ml/attachments/nanogpt-notebook.ipynb#W0sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mwith\u001b[39;00m ctx:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ammarh/Library/Mobile%20Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus%20Areas/ai-ml/attachments/nanogpt-notebook.ipynb#W0sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ammarh/Library/Mobile%20Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus%20Areas/ai-ml/attachments/nanogpt-notebook.ipynb#W0sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m         y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(x, max_new_tokens, temperature\u001b[39m=\u001b[39;49mtemperature, top_k\u001b[39m=\u001b[39;49mtop_k)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ammarh/Library/Mobile%20Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus%20Areas/ai-ml/attachments/nanogpt-notebook.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m         \u001b[39mprint\u001b[39m(decode(y[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ammarh/Library/Mobile%20Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus%20Areas/ai-ml/attachments/nanogpt-notebook.ipynb#W0sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus Areas/ai-ml/attachments/nanogpt_model.py:316\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, idx, max_new_tokens, temperature, top_k)\u001b[0m\n\u001b[1;32m    314\u001b[0m idx_cond \u001b[39m=\u001b[39m idx \u001b[39mif\u001b[39;00m idx\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mblock_size \u001b[39melse\u001b[39;00m idx[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mblock_size:]\n\u001b[1;32m    315\u001b[0m \u001b[39m# forward the model to get the logits for the index in the sequence\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m logits, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(idx_cond)\n\u001b[1;32m    317\u001b[0m \u001b[39m# pluck the logits at the final step and scale by desired temperature\u001b[39;00m\n\u001b[1;32m    318\u001b[0m logits \u001b[39m=\u001b[39m logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m/\u001b[39m temperature\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Mobile Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus Areas/ai-ml/attachments/nanogpt_model.py:181\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    179\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mdrop(tok_emb \u001b[39m+\u001b[39m pos_emb)\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mh:\n\u001b[0;32m--> 181\u001b[0m     x \u001b[39m=\u001b[39m block(x)\n\u001b[1;32m    182\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mln_f(x)\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m targets \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# if we are given some desired targets also calculate the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Mobile Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus Areas/ai-ml/attachments/nanogpt_model.py:104\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 104\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln_1(x))\n\u001b[1;32m    105\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(x))\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Mobile Documents/iCloud~md~obsidian/Documents/second-brain/2-Focus Areas/ai-ml/attachments/nanogpt_model.py:56\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m B, T, C \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize() \u001b[39m# batch size, sequence length, embedding dimensionality (n_embd)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# calculate query, key, values for all heads in batch and move head forward to be the batch dim\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m q, k, v  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc_attn(x)\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_embd, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     57\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(B, T, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head, C \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m# (B, nh, T, hs)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mview(B, T, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head, C \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m# (B, nh, T, hs)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/hf/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample from a trained model\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from nanogpt_model import GPTConfig, GPT\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'gpt2' # 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out' # ignored if init_from is not 'resume'\n",
    "start = \"Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'mps' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "# exec(open('configurator.py').read()) # overrides from command line or config file\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "elif init_from.startswith('gpt2'):\n",
    "    # init from a given GPT-2 model\n",
    "    model = GPT.from_pretrained(init_from, dict(dropout=0.0))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if compile:\n",
    "    model = torch.compile(model) # requires PyTorch 2.0 (optional)\n",
    "\n",
    "# look for the meta pickle in case it is available in the dataset folder\n",
    "load_meta = False\n",
    "if init_from == 'resume' and 'config' in checkpoint and 'dataset' in checkpoint['config']: # older checkpoints might not have these...\n",
    "    meta_path = os.path.join('data', checkpoint['config']['dataset'], 'meta.pkl')\n",
    "    load_meta = os.path.exists(meta_path)\n",
    "if load_meta:\n",
    "    print(f\"Loading meta from {meta_path}...\")\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        meta = pickle.load(f)\n",
    "    # TODO want to make this more general to arbitrary encoder/decoder schemes\n",
    "    stoi, itos = meta['stoi'], meta['itos']\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n",
    "else:\n",
    "    # ok let's assume gpt-2 encodings by default\n",
    "    print(\"No meta.pkl found, assuming GPT-2 encodings...\")\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "    decode = lambda l: enc.decode(l)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_ids: [24446, 502, 257, 1621, 546, 3619, 290, 22772, 508, 1816, 510, 262, 12788, 290, 550, 257, 1049, 2121, 866, 656, 262, 7850, 286, 27666, 25, 198]\n",
      "torch.Size([1, 26])\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "When Jack was a little boy, his father ran away and his mother didn't see him because her husband was down there. Jack was out on his own and was trying to get out of the house. His dad said, 'My son is coming down here and I can't help myself at that moment', so he went back down the hill and went down the hill to his father.\n",
      "\n",
      "People can call it madness, but with a lot of time and money to spend, it is. We are all one massive pile of bones of the human race.\n",
      "\n",
      "If you have any help, please ask.\n",
      "\n",
      "UPDATE: You can tell us what is the story of the abandoned boy in this photo.\n",
      "\n",
      "The Post's story is first posted on Thursday, February 9th, 2016.<|endoftext|>A group of women, mostly in their mid-30's, came together in Chicago on May 24 to hold a meetup for the next generation of gay men, and let their story shine a light on the growing movement to help those who might be discriminated against.\n",
      "\n",
      "According to the story by Melissa Miller, the group gathered at 4 p.m. to offer help and counsel for those whose lives have been jeopardized by discrimination and bigotry. \"We want to help them see that they have a voice, that they have a voice, that they have a chance to get out of their situation,\" Miller said.\n",
      "\n",
      "The group of women, mostly in their mid-30's, come together to offer help and counsel to those who might be affected by discrimination and bigotry.\n",
      "\n",
      "\"We want to tell them that they have a voice, that they have a voice, that they have a voice, that they have a voice, that they have a voice,\" Miller said.\n",
      "\n",
      "The group of women, mostly in their mid-30's, came together to offer help and counsel to those who might be affected by discrimination and bigotry.\n",
      "\n",
      "Although they have been silent about their stories, they have no doubt that they have been the catalyst that has created the conversation and been the catalyst that has delivered the crisis they're trying to address.\n",
      "\n",
      "\"I know not all of the cases in this country are the ones that are reversed, but the people that are affected by this show those kind of stories to be inspirational and have an impact,\" Rachel Rose, a Chicago-based co-founder of the group, told ProPublica.\n",
      "\n",
      "Rose said\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "My friend E'Thourien says that there was a very \"plucky\" bunch of men and women who washed up on top of the hill as they fought off the hordes of German invaders. It appears that an American soldier, a US Marine, the \"whisker\" of a bird with a white nose, is one of them.\n",
      "\n",
      "And the kicker? The battle of Waterloo's river, on June 18th, 1785, when 13,000 British soldiers were on the beach, and 2,000 British officers put their lives on the line, turned out to be one of the best battles of all time:\n",
      "\n",
      "The battle was fought on the back of a British Infantry Battalion, which was split up into two groups. These battalions were called \"soldiers\", who were sent to the front and then 'to fight the enemy, the enemy's army'.\" (E'Thourien, p. 71)\n",
      "\n",
      "Remember, it was a 2:2 French victory, only 4 minutes long. It was a big, big, huge battle war in, oh, the war of life. And if you haven't seen the most terrible of things, here are some of the things you probably didn't know about WWI.\n",
      "\n",
      "No one ever really knows the real meaning of the term, because it was introduced into the English language by the French and then used as shorthand for the war.\n",
      "\n",
      "\"We were, by the way, the only Irish unit at Waterloo. We were great on top of the hill,\" said a French officer named Jean Lacroix in the Battle of that town.\n",
      "\n",
      "\"It was a great battle. It was the last battle of a war that was not ours, which we were not going to win.\"\n",
      "\n",
      "When I read this quote, I thought that I was in for a shock. The phrase I was trying to define was \"the last battle that we even knew about.\" And I always thought that these two WWI battles of that same name meant something in common, because, well, the battle of Waterloo was the only battle in that war that we lost.\n",
      "\n",
      "The Battle of Waterloo\n",
      "\n",
      "In the spring of 1785, a couple of years before the British had even launched the attack on the South American country, a French battalion from Dien Bien Bien (also known as Bastille Day) had landed on the beach.\n",
      "\n",
      "It began with two important events\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "I had to come back here to open a bag and pull the bag out.\n",
      "\n",
      "\"I'm still working, I'm still out of time,\" Jack said of his work so he could find something to do.\n",
      "\n",
      "\"I am now training. I'm not doing this for the money. I'm doing it just to get my dream job,\" Jill said.\n",
      "\n",
      "\"I was in the bank doing the same thing. So I had to get a job. I'm a lawyer. I'm an accountant. I'm a secretary. I'm the best at this,\" Jack said.\n",
      "\n",
      "Jack looked at Jill, who was lying on a stick in the water with her hand in her jacket pocket.\n",
      "\n",
      "\"Look at that,\" Jack said to her.\n",
      "\n",
      "Jill's hand tingled, but Jack could tell the girl was feeling better.\n",
      "\n",
      "Jack looked at Jack again and again and again. He could see Jack was wearing a suit and tie and the same shirt.\n",
      "\n",
      "\"I'm going back out here,\" he said. \"I'm coming to get some information about a lady who I've seen at work and wanted to ask, but she walked off and got hurt and I lost my job. She came back to me and said I want all of my money back.\"\n",
      "\n",
      "\"I see there's a guy who was there, he said he's here to get more money,\" Jack told Jill.\n",
      "\n",
      "\"Yeah, he's here to get a job. It's better to get the money back, I'm not going to do that, and what I need to do is get some money and go a bit farther. I'll just do what I want to do to get it and make it. I used to work in the bank, so I have all these great things I like to do.\"\n",
      "\n",
      "\"Oh, Jack, look,\" Jill said.\n",
      "\n",
      "Jack's eyes opened wide.\n",
      "\n",
      "\"Look Jack, back here. I'll tell you this: I lost my job and I'll never make it again, and I'm going home to Florida and I want to get some money back and get to work a little more.\"\n",
      "\n",
      "\"That's very good, and I love working, and that's good.\"\n",
      "\n",
      "With that Jack headed out the door and headed for the bank.\n",
      "\n",
      "As he walked into the bank, Jack saw that the place was closed. Jack couldn't\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "http://tinyurl.com/2dz8v8o\n",
      "\n",
      "http://tinyurl.com/2dz83n4\n",
      "\n",
      "http://tinyurl.com/2dz9u2iQ\n",
      "\n",
      "http://tinyurl.com/2dz9g7bD\n",
      "\n",
      "https://www.youtube.com/watch?v=ZXFGz0T_E4Qg\n",
      "\n",
      "http://tinyurl.com/2dz9jhp6\n",
      "\n",
      "http://tinyurl.com/2dz9kgh6\n",
      "\n",
      "http://tinyurl.com/2dz9mxqw\n",
      "\n",
      "https://www.youtube.com/watch?v=t_Z0lk_B4Yw\n",
      "\n",
      "https://www.youtube.com/watch?v=-r8rAo8kDUs\n",
      "\n",
      "Most of the stories are \"not true\". This is probably just a coincidence, but for various reasons, most people will never see the light of day. A lot of people will only see the light of day, and that's one of the reasons why so many stories are \"not true\". For some reason, some of the accounts are made up, some are not, and others are a new thing altogether. I don't know if there are any other accounts that are so 100% true.\n",
      "\n",
      "What do you think of these stories? What do you think about the way they are described on Twitter or social media?\n",
      "\n",
      "Please leave a comment below with the piece you see.\n",
      "\n",
      "Source: Slate<|endoftext|>One of the most controversial topics in the history of the LDS Church has been the recent controversy over the issue of homosexuality being a sin.\n",
      "\n",
      "In all of modern Church history, it would appear that no one has written a systematic and comprehensive account of this matter. Many Christians, however, have been so taken for granted by the critics that they have been forced to engage in a series of long-overdue and scientifically invalid responses to what some would consider blatantly immoral changes made to the Church's traditional view of sexuality.\n",
      "\n",
      "The first step towards addressing a fundamental issue of Church history was the Restoration Era. During this time, there were many changes made that were fundamentally contrary to the Church's basic principles regarding sexual relations.\n",
      "\n",
      "The first revision of the Church doctrine regarding homosexuality was made by Bishop William C. Bowman in 18\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "Jack and Jill's story is about a hilltop summer camp south of Orlando. In the early afternoon I had taken Jack's camera out to capture Jack's face as I was heading up the hill. Jack will never forget this scene. His eyes were the most beautiful thing I could ever see. He was so focused, he would almost pull himself out of the snow by his side if he had to. I saw that Jack would lose it when he ran out of gas and, if he didn't, go up again for dinner with Jill. It was all going to shock Jack too. He would have to see Jill try to stop him. Once again, he was like the only boy in heaven. He was just dying to see his mom and dad.\n",
      "\n",
      "I could never understand why Jill would want to go up the next day, so I tried to stop her, which would make it seem to be pointless. But if I stopped her the next morning, it would have been so much worse. After that, Jill would just turn around and retreat to the other side of my camp. As she slept she would carry her camera back toward my tent. I wouldn't know about her, but Jill would be back that night. She would be telling me that she was so sad when she couldn't sleep, that she could't trust me anymore.\n",
      "\n",
      "Fortunately, the most my dad ever told me was true: he was happy, but it had been so much worse because of that day. But I wished I had known that his story would be shared so much. I didn't know Jack would tell me so much. I had always wondered how Jack could tell a story to Jill. But most of all I wished I had known how he could tell a story to Jill.\n",
      "\n",
      "In fact, I did hope that I would write about the \"other side\" of Jack and Jill. I hope that I would tell a story that Jill will never forget. I hope that my story will be shared with others who want to know more about Jack and Jill. And I hope that my story will inspire others who want to learn more about Jack and Jill.\n",
      "\n",
      "I hope that I will tell stories about our beloved Jack and Jill. I hope that I will share the stories with others who want to know more about Jack and Jill. I hope that I will share the stories with other people who want to know more about Jack and Jill.\n",
      "\n",
      "Jack and Jill by Chris\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "Jack and Jill: \"I think Jack is going to die, I'm going to die, I did it for a reason – but who am I going to take credit for? I don't see how his family would be able to do this to themselves, and I think we had it in us to get it. We had to find a way to make it work and still achieve what we wanted ourselves. And we had the idea to go and spend a million dollars. And we came up with the idea of leaving it to our children to be the real, creative creatures that they were. And we did that. They went on to have a great life and they were a hero to us …\"\n",
      "\n",
      "In the book that I've read, Jack and Jill are portrayed by the same man they were in. He is not a hero to anyone. The only thing that Jack and Jill are doing is throwing down. They're not fighting for anything. They are a hero.\n",
      "\n",
      "The thing about the book that they're doing is that they're performing a kind of moral act that is really, really important later on. They have to do it in a way that does not threaten the existence of the world.\n",
      "\n",
      "AMY GOODMAN: That's right. The man who killed Jack and Jill, Jack and Jill Stein, Jack and Ruth Stein, is a world-renowned human rights activist, a champion of independent thinking and a writer of \"strategic nonviolence\", a writer of \"strategic nonviolence\" in New York City who wrote his book about the impact of the Vietnam War. He's a professor of philosophy at the University of Central Lancashire. He's a friend and has read many books on his life.\n",
      "\n",
      "He joined Democracy Now! February 27th at 10am ET on Meet the Press. We'd also like to thank Barbara Dyer, NPR News, and Carol Dweck for reporting that interview.\n",
      "\n",
      "We're going to sit down with Barbara Dyer and talk about what's going on with the recent elections. We'll talk about her idea that we're losing the fight.\n",
      "\n",
      "BEV JONES: The president is saying that the electorate is fed up with politicians.\n",
      "\n",
      "BOZZE: I think elections are about the people – this is what's called the American people. They're fed up with what's going on and they're fed up with the parties. They don't want to be governed by the people\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "They looked up at their fallen heroes and cried out, \"Kill those damn fools!\" And how the devils saw what they were getting themselves into, one of them standing there and weeping, and the other, with his sword in his hand, saying, \"I am not worthy of the sword of God!\"\n",
      "\n",
      "So the first three stories are important in themselves, but the last three are a failure. They make little sense to me. They are essentially like what I find in other books. For example, I was reading an essay just now and the guy was using these words to describe a group of Greek and Roman intellectuals who had come from Macedonia and had gone up the hill to attack the Athenians, from the only place they had fought was the city of Troy. Sometimes the metaphors were used too long, but there were so many. \"They were the men who destroyed Troy and captured the men who were going to revolt\".\n",
      "\n",
      "Here is one scene, shortly after the battle with the Persians. The story is very similar to the one we talk about in the last one, in which the Athenians say they were being hunted down, and the Athenians beat them with swords. But the story that they say they were beaten is actually a legend. And it is this story that says that the Greeks were fighting the Persians and it is this story that is used the most by historians of this time.\n",
      "\n",
      "The second book, The Golden Age of Piraeus, is so full of mysteries that it is almost hard to understand. It is a short story about a young Greek woman who goes up to the Athenian city of Genoa and tells a story in which a little girl named Cassius, who is also a great Greek poet, tells her mother that she is going to learn about men who are in need.\n",
      "\n",
      "She takes off her shoes and carries the girls to a house where they will be taught their languages. In the house, the girls are taught to read, and the book is called the Golden Age of Piraeus. The first book of this story, The Golden Age of Piraeus, is still in print today, and several other stories are repeating itself.\n",
      "\n",
      "In the Greek languages, the idea that there was something different in Piraeus is very strong. Piraeus, as you know, is a city in its own right, and in its own right there are many places in the country where there are great monuments. There are many\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "\"I came back down to the beginning of our journey and saw the man that had taken the axe all the way up to the river and he ran to me and said, 'I am Jack and Jill, and we are going to cross the River of Hell.'\"\n",
      "\n",
      "\"And I said, 'Don't do it, Jack,' he said. I said, 'I'm not Jack and Jill. I'm Jack and I'm not going down to hell.'\"\n",
      "\n",
      "\"And he said, 'I want you to go with me to the bottom of the hill.'\n",
      "\n",
      "\"And I went out to the top of the hill.\"\n",
      "\n",
      "\"And I said, 'Jack, I want you to cross to the mouth of the river.' And he said, 'Not yet.'\n",
      "\n",
      "\"And I was going down to the mound.\n",
      "\n",
      "\"And he said, 'Eel, I am Jack and I'm running down to the river and seeing the things that go down through the graves. Surely you will have some bones in your hands.'\n",
      "\n",
      "\"And I said, 'Jack, that is not going to work out.\n",
      "\n",
      "\"And he said, 'With that I'm going down to the grave.' And I was just about going down.\"\n",
      "\n",
      "And what a story I heard. I don't know that day, I just know that it was the end of the moon, so I went down there and heard about it. And I was so excited by it that I went up into the world and I fell down there. I couldn't really put the word out to anyone but me. And I said, \"There's a big story here about Jack and Jill. I think we're going to do it together, there's a big story.\"…\n",
      "\n",
      "\"I felt so lucky to be up there with them. And I felt much happier about it. It was so important to me to do this. But I never said I was going to do it for them. I never said I was going to do it for myself. But I felt so lucky.\"\n",
      "\n",
      "You can read the whole story because it's available across multiple platforms.\n",
      "\n",
      "Share this: Twitter\n",
      "\n",
      "Facebook\n",
      "\n",
      "Google\n",
      "\n",
      "Reddit\n",
      "\n",
      "Tumblr\n",
      "\n",
      "Pinterest\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "Google\n",
      "\n",
      "Skype\n",
      "\n",
      "WhatsApp\n",
      "\n",
      "Pocket\n",
      "\n",
      "\n",
      "Like this: Like Loading...<|endoftext|>Photo via Flickr user Dr. Peter Jones\n",
      "\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "Tessie the Tugger\n",
      "\n",
      "Jack and Jill (from \"Pulp Fiction\") took a hike to the top of the mountain in a small Tugger, one of the only things that used to be close enough for them to walk (maybe) on their own. But as they went around, they found that the Tugger was too large. It was so big that it was frightening to them, and they just ran up to it. It was like a swamp with a clear trail leading back to the top. They weren't aware that it was a lake or sea, and they kept walking, and when they reached the top, they found that it was a very long way to the top.\n",
      "\n",
      "Advertisement\n",
      "\n",
      "They thought it was a little weird to the Waterman, but it was a very pleasant experience. It was very cold, and the trees were so smooth and healthy.\n",
      "\n",
      "The Tugger was named after the famous Italian ship, the Tuggeria, which was sunk off the coast of France in the 18th century. The Tugger is the name of a river of water in the same name of the River St. Lucie, which she uses in the movies Django Unchained and a few episodes of Ripper Street. The original name was derived from the Greek word lea, \"to flow.\" When it was first named, it was often found on the Bowers road, which was off the St. Lucie and was called the Tugger the same name that the first Tugger was named. After the Tugger was named, it became the name of the famous boat that was in the Bayonne river in 1845. In 1847, John D. Rockefeller won a race in the St. Louis race to win the title of a World-Winning President, after a long march down the St. Louis River to win the title of a World-Winning President. After winning, the J.W. was replaced by John D. Rockefeller Jr., who became America's first African-American President. The first World-Winning War ever took place in Africa, when American troops marched into the city of Zaire, then the capital of Liberia. In the middle of the fighting, 20,000 American troops were killed in an air strike by General Douglas MacArthur's Air Force. During this time period, a large portion of the continent was destroyed.\n",
      "\n",
      "Advertisement\n",
      "\n",
      "\n",
      "---------------\n",
      "Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\n",
      "\n",
      "A little after noon that afternoon Jack and Jill met the boy named Joe at a popular tavern in Pittsburgh. They shared a simple conversation and Joe, having lost his mother, was proud to own him. At first they didn't know that Joe was so handsome, but they soon became close, and Joe was the man he was known for. Joe was really simple, and he was always ready to talk with Jack. He always kept an eye on Jack, because they were growing very close. Jack told Jack about a old friend, a young old man named James. At that time, Jack and Jill had just gotten back from a trip to the mountains. Jack was very familiar with James, so he asked if he could meet him. Jack said yes, and then told James he had helped Jack get past the hill. When Jack had returned from his trip, James had turned him into a monster, and had killed him. Jack told his story to Jack and Jill. When Jack and Jill left, they carried a picture of James, while Jack, Jill, and Jack and Jack, Jill, were riding with Joseph on their backs.\n",
      "\n",
      "Jack and Jill would always tell stories about how Joseph would bring Jack with him, and how he would always take his hat with him when he left the country.\n",
      "\n",
      "Jack and Jill continued to tell the story of how Joe would always be with Joseph. Joseph would have an entire life, and Jack would always be with him. Jack was always his own man, and he was faithful to his father. He would always be a man to Jack, and always be fair and honest. Jack knew that Joe knew that he knew Joe well, and that Joe could be anything Joe wanted him to be. This is where Jack would get really interesting.\n",
      "\n",
      "Joseph introduced his sister to Joe. Joseph would be the one telling the story of the boys' first summer. He would come out of the woods to take the boys to the park, and he would call out to them. He would ask them if they had what they wanted and they would say yes. Eventually, the boys would join him and he would show them and tell them about his adventures. He would stay with them in the woods for days, and when he was finished, he would go out and do the same every day.\n",
      "\n",
      "A story told soon after in the newspapers, showed how Joseph would get away with murder. In one of the earliest reported stories, in 1893,\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "start = \"Tell me a story about Jack and Jill who went up the hill and had a great fall down into the river of doom:\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "\n",
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "print(f\"start_ids: {start_ids}\")\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "print(x.shape)\n",
    "\n",
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            y = model.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            print(decode(y[0].tolist()))\n",
    "            print('---------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
