---
aliases: []
tags:
---
# RLBench: The Robot Learning Benchmark & Learning Environment

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png)
### Metadata
Author: [[Stephen James, Zicong Ma, David Rovick Arrojo, Andrew J. Davison]]
Full Title: RLBench: The Robot Learning Benchmark & Learning Environment
Category: #readwise/articles
URL: https://arxiv.org/pdf/1909.12271.pdf
Date Highlighted: [[2024-09-20-Friday]]

## Highlights
- We present a challenging new benchmark and
  learning-environment for robot learning: RLBench. The bench-
  mark features 100 completely unique, hand-designed tasks
  ranging in difﬁculty, from simple target reaching and door
  opening, to longer multi-stage tasks, such as opening an oven
  and placing a tray in it. ([View Highlight](https://read.readwise.io/read/01gppvfbrp3ea4p1j8ews1yprr))
- This motivates the need for a one-size-ﬁts-all benchmark
  that allows the capability to utilise large-scale data, whilst
  also allowing classical systems to be compared. To that
  end, we present RLBench, which is an ambitious large-scale
  benchmark and learning environment designed to facilitate
  research in a number of both classical and deep-learning
  based robot manipulation areas. ([View Highlight](https://read.readwise.io/read/01gppvp8jkjfkt0kd4g1824fj2))
- This large-scale benchmark aims to
  accelerate progress in a number of vision-guided manipulation
  research areas, including: reinforcement learning, imitation
  learning, multi-task learning, geometric computer vision, and in
  particular, few-shot learning. With the benchmark’s breadth of
  tasks and demonstrations, we propose the ﬁrst large-scale few-
  shot challenge in robotics. ([View Highlight](https://read.readwise.io/read/01gppvj03m9knx696w3vz7ygtp))
- Provide the a large-scale few-shot challenge, where
  given M training tasks and N unseen tasks, a system
  must take K different demonstrations of each of the N
  unseen tasks, and then be able to perform these tasks
  in new conﬁgurations. ([View Highlight](https://read.readwise.io/read/01gppvqx2jdaf22yy88cpyycdw))
- whilst one could also equally argue that they are the same
  “pick up the X” task. ([View Highlight](https://read.readwise.io/read/01gppw3avq2pfwgmgst8kwkxnt))
    - Tags: #readwise/c2 
- RLBench employs 3 keys terms: Task, Variation, and
  Episode. Each task consists of one or more variations, and
  from each variation, an inﬁnite number of episodes can be
  drawn. ([View Highlight](https://read.readwise.io/read/01gppw0c30x1b9dtsxc7m6tpkp))
- We now motivate the need for the concept of a ‘variation’
  with an example. It is naturally difﬁcult to come up with
  a precise way to differentiate between tasks given their
  subjective nature. For example, one could argue that “pick
  up the apple” and “pick up the banana” are different tasks, ([View Highlight](https://read.readwise.io/read/01gppw320nq2h3yh2hsnzd1wd3))
    - Tags: #readwise/c1 
- The few pieces of work that perform few-shot learning in
  robotics [5], [6], [7] focused on a very narrow deﬁnition of
  task and often treat a variation of the same task as another
  task; for example, placing a peach into a red bowl would be
  considered a different task to placing an apple into a green
  bowl. ([View Highlight](https://read.readwise.io/read/01gppw7yj0q2mq09hvmn2gvkkz))
