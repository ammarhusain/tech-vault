---
aliases: []
tags:
---
# DINOv2: State-of-the-Art Computer Vision Models With Self-Supervised Learning

![rw-book-cover](https://scontent.ftpq3-1.fna.fbcdn.net/v/t39.2365-6/341008524_960886174936720_632340648951309797_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=iEomSus3K2cAX9cz1KH&_nc_ht=scontent.ftpq3-1.fna&oh=00_AfDEjzfsTxxentuO__8oIAcOEP1AV5-yNdnfFdvvxlIZMg&oe=6441F560)
### Metadata
Author: [[facebook.com]]
Full Title: DINOv2: State-of-the-Art Computer Vision Models With Self-Supervised Learning
Category: #readwise/articles
Document Tags: [ #readwise/doc/aiml,  #readwise/doc/AIML, ]
URL: https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/
Date Highlighted: [[2023-04-24-Monday]]

## Highlights
- Self-supervised learning — the same method that’s used to create cutting-edge large language models for text applications — is a powerful, flexible way to train AI models because it does not require large amounts of labeled data. Like with other self-supervised systems, models using the DINOv2 method can be trained on any collection of images, without needing any associated metadata. ([View Highlight](https://read.readwise.io/read/01gysz39znwxqssq6a8pvdcknm))
- DINOv2 provides high-performance features that can be directly used as inputs for simple linear classifiers. This flexibility means DINOv2 can be used to create multipurpose backbones for many different computer vision tasks. Our measurements show very strong prediction capabilities on tasks such as classification, segmentation, and image retrieval. ([View Highlight](https://read.readwise.io/read/01gysz5w483dbyk36szfg7ntwj))
- [Segment Anything](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/) is a promptable segmentation system focused on zero-shot generalization to diverse set of segmentation tasks. DINOv2 combines with simple linear classifiers to achieve strong results across multiple tasks beyond the segmentation sub-field, creating horizontal impact. ([View Highlight](https://read.readwise.io/read/01gyszct51etzfah0xwm8t8s2n))
- The performance of our approach is competitive or better than the performance of text-image models such as CLIP and OpenCLIP on a wide array of tasks, some of which are illustrated in our [demo](https://dinov2.metademolab.com/). ([View Highlight](https://read.readwise.io/read/01gyt0msy00xnw9peh9ybe5am6))
- Our features can be used out of the box for nearest neighbor classification or paired with linear classification, yielding strong performance. DINOv2 allows skipping the model adaptation phase (fine-tuning) — our linear evaluation performance is close to their fine-tuned counterpart ([View Highlight](https://read.readwise.io/read/01gyt0nnpzhgjbkgd8ec2b6pke))
