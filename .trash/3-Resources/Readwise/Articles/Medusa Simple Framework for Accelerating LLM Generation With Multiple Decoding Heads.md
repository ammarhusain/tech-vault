---
aliases: []
tags:
---
# Medusa: Simple Framework for Accelerating LLM Generation With Multiple Decoding Heads

![rw-book-cover](http://static1.squarespace.com/static/6358bea282189a0adf57fe16/t/64fea5e8635d7639ba8a5629/1694410218945/media.png?format=1500w)
### Metadata
Author: [[Tianle Cai*, Yuhong Li*, Zhengyang Geng, Hongwu Peng, Tri Dao (* Equal contribution)]]
Full Title: Medusa: Simple Framework for Accelerating LLM Generation With Multiple Decoding Heads
Category: #readwise/articles
URL: https://together.ai/blog/medusa
Date Highlighted: [[2023-10-04-Wednesday]]

## Highlights
- While methods like [speculative decoding](https://arxiv.org/abs/2302.01318) have been proposed to accelerate the generation speed, their intricate nature has left many in the open-source community hesitant to embrace them. ([View Highlight](https://read.readwise.io/read/01hbye027yg5jf4x609m64q7f5))
- Medusa can improve the generation efficiency of LLMs by about 2x. ([View Highlight](https://read.readwise.io/read/01hbydzaytkwr6hnjx9emn3d4b))
- The figure below offers a visual breakdown of the Medusa pipeline for those curious about the nuts and bolts.
  ![](https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/cdea2970-4a27-4dd4-b472-86e7d07fe263/Medusa.drawio.png) ([View Highlight](https://read.readwise.io/read/01hbydyy694rwh6j0kjpskbhfc))
