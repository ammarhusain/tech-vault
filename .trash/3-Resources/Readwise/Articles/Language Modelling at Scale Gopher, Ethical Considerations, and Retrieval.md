---
aliases: []
tags:
---
# Language Modelling at Scale: Gopher, Ethical Considerations, and Retrieval

![rw-book-cover](https://assets-global.website-files.com/621e749a546b7592125f38ed/622216be01a2ee7d876bba4f_LLM.jpg)
### Metadata
Author: [[deepmind.com]]
Full Title: Language Modelling at Scale: Gopher, Ethical Considerations, and Retrieval
Category: #readwise/articles
URL: https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval
Date Highlighted: [[2022-12-04-Sunday]]

## Highlights
- Our research investigated the strengths and weaknesses of those different-sized models, highlighting areas where increasing the scale of a model continues to boost performance – for example, in areas like reading comprehension, fact-checking, and the identification of toxic language. We also surface results where model scale does not significantly improve results — for instance, in logical reasoning and common-sense tasks. ([View Highlight](https://read.readwise.io/read/01gkezhsxn153f6z7s3fg7pvkv))
- ![](https://assets-global.website-files.com/621e749a546b7592125f38ed/6224d01f62cce9f8638e7d78_Fig%201.svg)
  Performance on the Massive Multitask Language Understanding (MMLU) benchmark broken down by category. Gopher improves upon prior work across several categories. ([View Highlight](https://read.readwise.io/read/01gkezjpz0d4f4vbhgnh7yx90f))
- The taxonomy we present serves as a foundation for experts and wider public discourse to build a shared overview of ethical and social considerations on language models, make responsible decisions, and exchange approaches to dealing with the identified risks.
  ![](https://assets-global.website-files.com/621e749a546b7592125f38ed/6224d06f425601d8baac2b6b_Fig%204.svg) ([View Highlight](https://read.readwise.io/read/01gkezwx4ftf710c5mpzen1h1r))
- language models are known to reproduce harmful social stereotypes, but research on this problem is still in early stages, as a [recent DeepMind paper](https://deepmind.com/research/publications/2021/Challenges-in-Detoxifying-Language-Models) showed. ([View Highlight](https://read.readwise.io/read/01gkezw1cvzzb4gxf406zpw1sp))
- RETRO efficiently queries for passages of text to improve its predictions. By comparing generated texts to the passages RETRO relied upon for generation, we can interpret why the model makes certain predictions and where they came from. ([View Highlight](https://read.readwise.io/read/01gkezzgtdsyh7gs663kwzg22w))
- ![](https://assets-global.website-files.com/621e749a546b7592125f38ed/6224d07ff43a03f5048d6d4e_Fig%205.svg) ([View Highlight](https://read.readwise.io/read/01gkf00kacsa7fs4rs38qj6hmh))
