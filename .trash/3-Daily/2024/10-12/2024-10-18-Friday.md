---
alias: ["Friday, Oct 18, 2024"]
tags: 
---
# TOP-OF-MIND
- #aiml #j595  
	- [OpenAI Model Distillation: A Guide With Examples | DataCamp](https://www.datacamp.com/tutorial/model-distillation-openai)
		- Pretty straightforward - (i) just store=True for prompt completions, (ii) use Evals to measure results as graded by GPT4o and (iii) run distillation of some small base model and eval again
		- Not sure if it is just doing fintuning like [[tinkering#Openai Gpt-3 Chatbot]] or actually learning the output distribution of the teacher model from the softmax layer
	- [GPT-4o Vision Fine-Tuning: A Guide With Examples | DataCamp](https://www.datacamp.com/tutorial/gpt-4o-vision-fine-tuning)
		- Similar API as what I had used to built the [[tinkering#Openai Gpt-3 Chatbot]] in mid 2022 - using the finetuning API and JSONL file for prompts and completions
	- [Experimenting with audio input and output for the OpenAI Chat Completion API](https://simonwillison.net/2024/Oct/18/openai-audio/)
	- [AI - 2024AD: 212-page Report (from this morning) Fully Read w/ Highlights - YouTube](https://www.youtube.com/watch?v=CyOL_4K2Nyo)
		- Highlights copyright issues and how creators are warming upto it with companies jumping into licensing monetization (Created by Humans, Calliope networks) - [[Crawlspace]]
			- Zuckerberg claims content creators might overestimate how valuable that data is in model training
	- [Llama 3.2: Revolutionizing edge AI and vision with open, customizable models](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)
	- Probably have this in [[*shiny-fm-llm]]: 
		- Llama-1 was just a pretrained generation model, 
		- Alpaca was instruction finetuned on Llama-1 - its performance was matching OpenAIs text-davinci-003 (InstructGPT model),
		- Vicuna was finetuned Alpaca using ShareGPT (dataset collected from ChatGPT) and was a chatbot
		- Llava is simply a vision-encoder + projection-layer + Vicuna-LLM
			- Vision encoder is off the shelf pretrained. Llava training involved 2 stages
				- Stage 1: Pretraining for Feature alignment: Trains the projection layer weights to align text & vision
				- Stage 2: Fine-tuning End-to-end: Trains the projection layer + Vicuna LLM weights
	- [GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML Compilation](https://github.com/mlc-ai/mlc-llm)
		- Helps you deploy LLMs across diverse hardware: GPUs (NVIDIA, AMD, Apple, Intel), CPUs, and web browsers. It uses ML compilation to optimize performance. You can run models like Llama 2 and Vicuna on your chosen device with OpenAI-compatible APIs.
	
- #social 
	- Pizza making night with Anayah & Mahira
# TASKS COMPLETED TODAY
%% TCT_TEMPLATED_START 2024-10-18 00:00 %%
%% TCT_TEMPLATED_END 2024-10-18 23:59 %%


# NOTES CREATED IN THE LAST WEEK
``` dataview
TABLE file.folder AS Folder, file.ctime As Created
WHERE file.ctime >= date(substring(this.file.name,0,10)) - dur(1 week) 
AND file.ctime < date(substring(this.file.name,0,10)) 
AND file.folder != "Daily"
SORT file.mtime ASCENDING
```

# NOTES MODIFIED IN THE LAST WEEK
``` dataview
TABLE file.folder AS Folder, file.mtime AS Modified, file.ctime AS Created
WHERE file.mtime >= date(substring(this.file.name,0,10)) - dur(1 week)
AND file.mtime < date(substring(this.file.name,0,10))
AND file.ctime < date(substring(this.file.name,0,10)) - dur(1 week)
AND file.folder != "Daily"
SORT file.mtime ASCENDING
```
---
