---
aliases:
  - 2024-06-03-Monday
tags: 
---
**[DayOne](dayone://open?date=2024-06-03)**

# TOP-OF-MIND
- #j595/journal 
	- Got the finetuned model generation and evaluation working. It does pretty well so far with no grammar in aligning with the gazing > 50% rule.
	- However it seems like SFTTrainer uses the same next token prediction loss on both the prompt & completion. I would have expected it to zero out gradients in the prompt but it does not.
	- Found some interesting [[hugging face]] resources here for finetuning [[LoRA#Finetuning Libraries]]: [GitHub - huggingface/alignment-handbook: Robust recipes to align language models with human and AI preferences](https://github.com/huggingface/alignment-handbook)
	- [x] #j595/todo get dataCollatorForCompletionsOnly working and test out [completed:: [[2024-06-04-Tuesday]]]
- #journal/daily 
# NOTES CREATED IN THE LAST WEEK
``` dataview
TABLE file.folder AS Folder, file.ctime As Created
WHERE file.ctime >= date(substring(this.file.name,0,10)) - dur(1 week) 
AND file.ctime < date(substring(this.file.name,0,10)) 
AND file.folder != "Daily"
SORT file.mtime ASCENDING
```

# NOTES MODIFIED IN THE LAST WEEK
``` dataview
TABLE file.folder AS Folder, file.mtime AS Modified, file.ctime AS Created
WHERE file.mtime >= date(substring(this.file.name,0,10)) - dur(1 week)
AND file.mtime < date(substring(this.file.name,0,10))
AND file.ctime < date(substring(this.file.name,0,10)) - dur(1 week)
AND file.folder != "Daily"
SORT file.mtime ASCENDING
```
---
