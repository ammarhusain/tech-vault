---
aliases: [2021-11-09]
created: 2022-10-25-Tuesday 05:19
modified: 2023-03-10-Friday 23:15
tags: 
---


---

# Quote
> The industrial landscape is already littered with remains of once successful companies that could not adapt their strategic vision to altered conditions of competition.
> — <cite>Ralph Abernathy</cite>

# Top-of-mind
- [TOCC presentation](https://docs.google.com/presentation/d/1SN-Q_vFxljeZaBdbn0h9JC8Zo-bePhXP4sAGl33SM5A/edit?resourcekey=0-sQKmZys866K_UZesIjk6xg#slide=id.gd5278b9f66_1_543) for calibration
	- Good morning folks! I will be presenting for Perception today and we have a bunch of exciting updates and results on the calibration front.

		  The gif you see on the left illustrates the difference between using calibrated robots to generate HiFi maps vs non-calibrated ones. The cleaner & denser reconstruction clearly demonstrates the impact of quality calibration routines both in HW and SW.
		  
		  For this set of experiments we calibrated 3 robots in the cube using a colab that is being translated to the Hardware Test Framework (HTF) this quarter. These calibration routines estimate the various intrinsic and extrinsic parameters of all the cameras and camera pairs along with the CBr for robust association & registration of sensor measurements.
		  
		  We hope to roll this calibration out across the fleet in Q1 2022, and are in the process of validating the robustness and impact of the calibration algorithms which is where these experiments are really helpful.
		  
		  Another experiment on the right gif that Korbinian ran was on full body kinematics calibration. This is the calibration of the full chain of joints starting with the pan tilt head to the arm and all the way to the gripper. In the video we see the robot gripper holding a fiducial. The observation of the fiducial in the camera images serves as ground truth while the forward kinematic projection of it is where the robot believes its gripper is. When no calibration was applied it resulted in a reprojection error of 40pix, while when the pan tilt head was calibrated it was 18 and with full body down to 6 pixels. Although these metrics aren’t intuitive in terms of robot performance they do prove that we can drastically improve our estimates with full body calibration.
		  
		  The next steps here are that we need to make sure we've got all the right metrics in place to measure calibration efficacy, and finalizing a Python API that wraps all the C++ algorithms so they can be used in the python-based HTF framework. There's also a lot of work going on to stabilize the cube as a text fixture, including modifying and automating the lights, and experimenting with lighting conditions to ensure we always get good results.
		  
		  And that’s it for perception

---

# Vault Updates

**Notes created in the last week:**

``` dataview
TABLE file.folder AS Folder, file.ctime As Created
WHERE file.ctime >= date(substring(this.file.name,0,10)) - dur(1 week) AND file.ctime < date(substring(this.file.name,0,10))
SORT file.mtime ASCENDING
```

**Notes modified in the last week:**

``` dataview
TABLE file.folder AS Folder, file.mtime AS Modified, file.ctime AS Created
WHERE file.mtime >= date(substring(this.file.name,0,10)) - dur(1 week)
AND file.mtime < date(substring(this.file.name,0,10))
AND file.ctime < date(substring(this.file.name,0,10)) - dur(1 week)
SORT file.mtime ASCENDING
```
---
