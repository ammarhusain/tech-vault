---
aliases: [2023-11-07]
tags: 
---
**[DayOne](dayone://open?date=2023-11-07)**

# TOP-OF-MIND
- #j595/journal 
	- Questions for CometML product demo:
		- If I have a production service logging metrics - does it also need an account with an API key?
		- How to log a model and a dataset in CometML?
		- Can I run model inference on a hosted model through the CometML app? - REST API or local llama-cpp?
		- Within the frontend - how an I pick certain prompts and rerun inference on them? Or pick certain datasets to rerun inference?
		- ---
		- Product demo from JAcques - no real surprises. More less makes sense
	- Xin has a 1B model trained with 2000 data samples.
		- [x] #j595/todo Find out how he trained it and what model? ✅ 2023-11-08
	- [x] #j595/todo Upload Xins photographer dataset to comet [completed:: [[2023-11-09-Thursday]]]
	- [x] #j595/todo Experiment and play around with Comets LLM features [completed:: [[2024-01-09-Tuesday]]]
	- [x] #j595/todo Figure out how to put Comet server behind Shield - with Andreas' help. [completed:: [[2023-11-09-Thursday]]]
	- 
	- Used this [git command ](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/removing-sensitive-data-from-a-repository)to clear out large files from repo - `git filter-repo --invert-paths --path PATH-TO-YOUR-FILE-WITH-SENSITIVE-DATA`
	- [Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments - Lightning AI](https://lightning.ai/pages/community/lora-insights/#toc11)
		- This article explored the various knobs we can tune when training custom LLMs using LoRA. We found that QLoRA is a great memory-saver even though it comes at an increased runtime cost.
		- The best bang for the buck can be achieved by optimizing the LoRA settings, including the rank. Increasing the rank will result in more trainable parameters, which could lead to higher degrees of overfitting and runtime costs. However, when increasing the rank, choosing the appropriate alpha value is important. 
		- [x] #j595/todo Use the [Lit-GPT library](https://github.com/Lightning-AI/lit-gpt) to finetune a model ✅ 2024-01-09
		- [ ] 

- #journal/daily 
	- Took a long afternoon nap again

# TASKS
```dataviewjs
const date = `${dv.current().file.name}`
const query1 = `(has happens date) OR (has due date) OR (has scheduled date) OR (has done date) OR (has created date)`
const query2 = `(done on ` + date + `) OR (due on ` + date + `) OR (scheduled on ` + date + `) OR (happens on ` + date + `) OR (created on ` + date + `)`
dv.paragraph('```tasks\n ' + query1 + '\n' + query2 + '\n```');
```
# CROSS-REFERENCED 
```dataviewjs
// Loop through pages 
for (let p of dv.pages()) {
	for (let ol of p.file.outlinks) {
		// find all the cross references of this file
		if (dv.current().file.path == ol.path) {
			// get all the lists in this file
			for (let ls of p.file.lists) {
				if (ls.text.includes(dv.current().file.name)) {
					dv.header(3, p.file.link + "  ...  " + ls.line)
					dv.paragraph(ls.text)
					dv.paragraph("---")
				}
			}
		}
	}
}
```

# VAULT UPDATES
## NOTES CREATED IN THE LAST WEEK
``` dataview
TABLE file.folder AS Folder, file.ctime As Created
WHERE file.ctime >= date(substring(this.file.name,0,10)) - dur(1 week) AND file.ctime < date(substring(this.file.name,0,10))
SORT file.mtime ASCENDING
```

## NOTES MODIFIED IN THE LAST WEEK
``` dataview
TABLE file.folder AS Folder, file.mtime AS Modified, file.ctime AS Created
WHERE file.mtime >= date(substring(this.file.name,0,10)) - dur(1 week)
AND file.mtime < date(substring(this.file.name,0,10))
AND file.ctime < date(substring(this.file.name,0,10)) - dur(1 week)
SORT file.mtime ASCENDING
```
---
