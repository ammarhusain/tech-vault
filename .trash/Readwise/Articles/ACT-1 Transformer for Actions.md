---
aliases: 
tags:
  - readwise/doc/aiml
---
# ACT-1: Transformer for Actions

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png)
### Metadata
Author: [[adept.ai]]
Full Title: ACT-1: Transformer for Actions
Category: #readwise/articles
Document Tags: [ [[AIML]], ]
URL: https://www.adept.ai/blog/act-1
Date Highlighted: [[2023-04-01-Saturday]]

## Highlights
- At Adept, we are building the next frontier of models that can take actions in the digital world—that’s why we’re excited to introduce our first large model, Action Transformer (ACT-1). ([View Highlight](https://read.readwise.io/read/01gwyhkkfam2fa9vacnfnjjn7s))
- Most interaction with computers will be done using natural language, not GUIs. We’ll tell our computer what to do, and it’ll do it. Today’s user interfaces will soon seem as archaic as landline phones do to smartphone users. ([View Highlight](https://read.readwise.io/read/01gwyhb0m49b3wcyfdw95xv6na))
    - Note: Interesting point. Though arent these ACT-1 foundation models trained using the user clicking through these GUI interfaces? 
      What is UIs get updated how well does this model do? 
      How will it be trained if the UI elements for intermediate steps say dont exist and it spits out a final answer?
---
aliases: []
tags:
---
# ACT-1: Transformer for Actions

![rw-book-cover](https://www.adept.ai/images/blog/act-1/hero.webp)
### Metadata
Author: [[adept.ai]]
Full Title: ACT-1: Transformer for Actions
Category: #readwise/articles
Document Tags: [ #readwise/doc/aiml,  #readwise/doc/AIML, ]
URL: https://www.adept.ai/blog/act-1
Date Highlighted: [[2023-04-01-Saturday]]

## Highlights
- At Adept, we are building the next frontier of models that can take actions in the digital world—that’s why we’re excited to introduce our first large model, Action Transformer (ACT-1). ([View Highlight](https://read.readwise.io/read/01gwyhkkfam2fa9vacnfnjjn7s))
- Most interaction with computers will be done using natural language, not GUIs. We’ll tell our computer what to do, and it’ll do it. Today’s user interfaces will soon seem as archaic as landline phones do to smartphone users. ([View Highlight](https://read.readwise.io/read/01gwyhb0m49b3wcyfdw95xv6na))
    - Note: Interesting point. Though arent these ACT-1 foundation models trained using the user clicking through these GUI interfaces? 
      What is UIs get updated how well does this model do? 
      How will it be trained if the UI elements for intermediate steps say dont exist and it spits out a final answer?

