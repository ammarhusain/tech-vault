---
aliases: []
tags:
---
# Gradient Update #24: Robotaxis in Beijing and a Multi-Task Visual Language Model

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)
### Metadata
Author: [[thegradientpub.substack.com]]
Full Title: Gradient Update #24: Robotaxis in Beijing and a Multi-Task Visual Language Model
Category: #readwise/articles
URL: https://thegradientpub.substack.com/p/gradient-update-24-robotaxis-in-beijing
Date Highlighted: [[2022-07-01-Friday]]

## Highlights
- Flamingo integrates a powerful pretrained language model and vision model into a single framework, thus taking advantage of well-understood single modality foundation models. For  language, Flamingo uses a pretrained Chinchilla language model with 70 billion parameters. For vision, Flamingo uses a contrastively pretrained Normalizer Free ResNet (NFNet) with 435 million parameters. During training, the parameters of these two models are frozen. And once it’s complete, Flamingo can be directly adapted to vision tasks via simple few-shot learning without any additional task-specific finetuning.

