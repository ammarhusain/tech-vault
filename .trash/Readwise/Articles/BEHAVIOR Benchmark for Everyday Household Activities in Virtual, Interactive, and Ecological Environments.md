---
aliases: 
tags:
  - readwise/doc/aiml
---
# BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)
### Metadata
Author: [[Anonymous Submission]]
Full Title: BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments
Category: #readwise/articles
URL: https://arxiv.org/pdf/2108.03332.pdf
Date Highlighted: [[2023-01-12-Thursday]]

## Highlights
- We introduce BEHAVIOR, a benchmark for embodied AI with 100
  activities in simulation, spanning a range of everyday household chores such as
  cleaning, maintenance, and food preparation. These activities are designed to be
  realistic, diverse and complex, aiming to reproduce the challenges that agents must
  face in the real world. ([View Highlight](https://read.readwise.io/read/01gphq98jj4ss9txj1d0vbybmy))
- There are three major challenges that have prevented existing
  benchmarks to accommodate more realistic, diverse, and complex activities:
  • Deﬁnition: Identifying and deﬁning meaningful activities for benchmarking;
  • Realization: Developing simulated environments that realistically support such activities;
  • Evaluation: Deﬁning success and objective metrics for evaluating performance. ([View Highlight](https://read.readwise.io/read/01gphsvevjj6sy71tk59qmka1v))
- we provide a comprehensive set of metrics to evaluate
  agent performance in terms of success and efﬁciency. To make evaluation comparable across diverse
  activities, scenes, and instances, we propose a set of metrics relative to demonstrated human per-
  formance on each activity, and provide a large-scale dataset of 500 human demonstrations ([View Highlight](https://read.readwise.io/read/01gphrtb60gtv1nwa5ap20xvb4))
- Although real-world challenges [45–52] provide the ultimate
  testbed for embodied AI agents, benchmarks in simulated environments serve as useful alternatives
  with several advantages; simulation enables faster, safer learning, and supports more reproducible,
  accessible, and fair evaluation. ([View Highlight](https://read.readwise.io/read/01gphs5q2wj0j2834rxe6t23kt))
- we use the American Time Use Survey (ATUS, [33]): A survey
  from the U.S. Bureau of Labor Statistics on how Americans spend their time. BEHAVIOR activities
  come from, and are distributed similarly to, the full space of simulatable activities in ATUS ([View Highlight](https://read.readwise.io/read/01gphs0frt9fkfqjepbcrqezy8))
- The main goal of an embodied AI agent in BEHAVIOR is
  to perform an activity successfully (i.e., all logical expressions in the goal condition are met). A
  binary deﬁnition of success, however, only signals the end of a successful execution and cannot assess
  interim progress. ([View Highlight](https://read.readwise.io/read/01gphtkqq18xqhcvd08cmbwrdj))
- We presented BEHAVIOR, a novel benchmark for embodied AI solutions of household activities.
  BEHAVIOR presents 100 realistic, diverse and complex activities with a new logic-symbolic represen-
  tation, a fully functional simulation-based implementation, and a set of human-centric metrics based
  on the performance of humans on the same activities in VR. ([View Highlight](https://read.readwise.io/read/01gphv13x60xh7ven4mqrsh38y))
- We presented BEHAVIOR, a novel benchmark for embodied AI solutions of household activities.
  BEHAVIOR presents 100 realistic, diverse and complex activities with a new logic-symbolic represen-
  tation, a fully functional simulation-based implementation, and a set of human-centric metrics based
  on the performance of humans on the same activities in VR. ([View Highlight](https://read.readwise.io/read/01gphv19f1mf79f8kztdtv43d3))
- BEHAVIOR is a benchmark in simulation. This facilitates a continuous evaluation of solutions,
  fair and equal conditions, and increased accessibility without expensive robot hardware. It is also
  instrumental for modern robot learning procedures that require generating large amount of experiences.
  However, the use of simulation introduces a gap between the activities in our benchmark and the
  equivalent activities in real world. ([View Highlight](https://read.readwise.io/read/01gphvdgxhtq5hxtmhk61k0nmx))

