---
aliases: []
tags:
---
# Socratic Models: Composing Zero-Shot Multimodal Reasoning With Language

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png)
### Metadata
Author: [[socraticmodels.github.io]]
Full Title: Socratic Models: Composing Zero-Shot Multimodal Reasoning With Language
Category: #readwise/articles
URL: https://socraticmodels.github.io/
Date Highlighted: [[2022-04-08-Friday]]

## Highlights
- Socratic Models (SMs), a framework that uses structured dialogue between pre-existing foundation models, each of which can exhibit unique (but complementary) capabilities depending on the distributions of data on which they are trained. On various perceptual tasks, this work presents a case study of SMs with visual language models (VLMs, e.g., CLIP), large language models (LMs, e.g., GPT-3, RoBERTa), and audio language models (ALMs, e.g., Wav2CLIP, Speech2Text). From video search, to image captioning; from generating free-form answers to contextual reasoning questions, to forecasting future activities â€“ SMs can provide meaningful results for complex tasks across classically challenging computer vision domains, without any model finetuning.

