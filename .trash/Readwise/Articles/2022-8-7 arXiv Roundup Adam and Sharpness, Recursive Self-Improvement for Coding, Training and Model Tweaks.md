---
aliases: 
tags:
  - readwise/doc/aiml
---
# 2022-8-7 arXiv Roundup: Adam and Sharpness, Recursive Self-Improvement for Coding, Training and Model Tweaks

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)
### Metadata
Author: [[dblalock.substack.com]]
Full Title: 2022-8-7 arXiv Roundup: Adam and Sharpness, Recursive Self-Improvement for Coding, Training and Model Tweaks
Category: #readwise/articles
URL: https://dblalock.substack.com/p/2022-8-7-arxiv-roundup-adam-and-sharpness?utm_medium=email
Date Highlighted: [[2022-09-21-Wednesday]]

## Highlights
- Language Models Can Teach Themselves to Program BetterTo teach models to program, you used to give them a natural language prompt. But recent work has shown that you can instead just show them a unit test and tell them to generate a program that satisfies it (a “programming puzzle”). This is way nicer because it’s simpler and you can just run the code to see if it works.

