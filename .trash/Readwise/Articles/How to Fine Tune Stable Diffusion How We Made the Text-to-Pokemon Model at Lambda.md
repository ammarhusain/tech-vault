---
aliases: []
tags:
---
# How to Fine Tune Stable Diffusion: How We Made the Text-to-Pokemon Model at Lambda

![rw-book-cover](https://lambdalabs.com/hubfs/Untitled%20design.png#keepProtocol)
### Metadata
Author: [[Justin Pinkney]]
Full Title: How to Fine Tune Stable Diffusion: How We Made the Text-to-Pokemon Model at Lambda
Category: #readwise/articles
URL: https://lambdalabs.com/blog/how-to-fine-tune-stable-diffusion-how-we-made-the-text-to-pokemon-model-at-lambda
Date Highlighted: [[2023-04-18-Tuesday]]

## Highlights
- getting results in a particular style or appearance often involves a lot of work "prompt engineering". If you have a particular type of image you'd like to generate, then an alternative to spending a long time crafting an intricate text prompt is to actually fine tune the image generation model itself. ([View Highlight](https://read.readwise.io/read/01gyand16xecqhazn6qzvy7cat))
- Instead of painstakingly writing out captions ourselves we're going to use a neural network to do the hard work for us, specifically an image captioning model called [BLIP](https://github.com/salesforce/BLIP). ([View Highlight](https://read.readwise.io/read/01gyandh15fjg9d7a1pdrhge7r))
---
aliases: []
tags:
---
# How to Fine Tune Stable Diffusion: How We Made the Text-to-Pokemon Model at Lambda

![rw-book-cover](https://lambdalabs.com/hubfs/Untitled%20design.png#keepProtocol)
### Metadata
Author: [[Justin Pinkney]]
Full Title: How to Fine Tune Stable Diffusion: How We Made the Text-to-Pokemon Model at Lambda
Category: #readwise/articles
URL: https://lambdalabs.com/blog/how-to-fine-tune-stable-diffusion-how-we-made-the-text-to-pokemon-model-at-lambda
Date Highlighted: [[2023-04-18-Tuesday]]

## Highlights
- getting results in a particular style or appearance often involves a lot of work "prompt engineering". If you have a particular type of image you'd like to generate, then an alternative to spending a long time crafting an intricate text prompt is to actually fine tune the image generation model itself. ([View Highlight](https://read.readwise.io/read/01gyand16xecqhazn6qzvy7cat))
- Instead of painstakingly writing out captions ourselves we're going to use a neural network to do the hard work for us, specifically an image captioning model called [BLIP](https://github.com/salesforce/BLIP). ([View Highlight](https://read.readwise.io/read/01gyandh15fjg9d7a1pdrhge7r))

